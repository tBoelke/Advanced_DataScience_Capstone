{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# 3. Feature Engineering Pipeline Modules #\n## ( reused from previous step )##", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190904164903-0000\nKERNEL_ID = 80ba139d-1e5b-4652-9998-2caa2619c049\n"
                }
            ], 
            "source": "import pandas as pd\nimport numpy as np\n# df = pd.read_csv('\\Coursera\\Advanced_DS_Capstone_02.csv', index_col=[0])\ndf = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header = None)\ndf.columns = [\"Feature_1\", \"Feature_2\", \"Feature_3\", \"Feature_4\", \"Label\"]"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.feature import StringIndexer\nspark_df = sqlContext.createDataFrame(df)\nindexer = StringIndexer(inputCol=\"Label\", outputCol=\"LabelIndex\")\n\nfrom pyspark.ml.feature import OneHotEncoderEstimator\nencoder = OneHotEncoderEstimator(inputCols=[\"LabelIndex\"], outputCols=[\"LabelVec\"])\n\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nvectorAssembler = VectorAssembler(inputCols=[\"Feature_1\",\"Feature_2\",\"Feature_3\", \"Feature_4\"],\n                                  outputCol=\"FeaturesVec\")\n\nfrom pyspark.ml.feature import Normalizer\nnormalizer = Normalizer(inputCol=\"FeaturesVec\", outputCol=\"FeaturesNorm\", p=1.0)"
        }, 
        {
            "source": "# 4. Model Definition Pipelines #\n## 4.1 Multilayer-Perceptron-Classifier ##", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import MultilayerPerceptronClassifier\nmlp = MultilayerPerceptronClassifier(labelCol=\"LabelIndex\", featuresCol=\"FeaturesNorm\", maxIter=100, layers=[4, 3, 3], blockSize=1, seed=123)\npipelineMLP = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, mlp])"
        }, 
        {
            "source": "## 4.2 Decision-Tree-Classifier ##", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.classification import DecisionTreeClassifier\ndt = DecisionTreeClassifier(labelCol=\"LabelIndex\", featuresCol=\"FeaturesNorm\")\npipelineDT = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, dt])"
        }, 
        {
            "source": "## 4.3 Random-Forest-Classifier ##", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"LabelIndex\", featuresCol=\"FeaturesNorm\", numTrees=10)\npipelineRF = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, rf])"
        }, 
        {
            "source": "# 5. Model Training and Evaluation #\n## 5.1 Using Splitting in Train and Test Data ##\n### 5.1.1 Randomly Splitting the Data ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 46, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "splits = spark_df.randomSplit([0.85, 0.15])\ndf_train = splits[0]\ndf_test = splits[1]"
        }, 
        {
            "source": "### 5.1.2 Normal Training on df_train###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 47, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "modelMLP = pipelineMLP.fit(df_train)\nmodelDT = pipelineDT.fit(df_train)\nmodelRF = pipelineRF.fit(df_train)"
        }, 
        {
            "source": "### 5.1.3 Evaluation on df_train and df_test ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 48, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 48, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MultiLayerPerceptron</th>\n      <th>DecisionTree</th>\n      <th>RandomForest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>normal_df_train</th>\n      <td>0.976744</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>normal_df_test</th>\n      <td>0.952381</td>\n      <td>0.904762</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>crossVal_df_train</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>crossVal_df_test</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                  MultiLayerPerceptron DecisionTree RandomForest\nnormal_df_train               0.976744            1            1\nnormal_df_test                0.952381     0.904762     0.952381\ncrossVal_df_train                  NaN          NaN          NaN\ncrossVal_df_test                   NaN          NaN          NaN"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nmultiEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"LabelIndex\")\nresults = pd.DataFrame(columns = ['MultiLayerPerceptron', 'DecisionTree', 'RandomForest'], index =['normal_df_train', 'normal_df_test', 'crossVal_df_train', 'crossVal_df_test']) \nprediction = modelMLP.transform(df_train)\nresults.iloc[0,0] = multiEval.evaluate(prediction)\nprediction = modelDT.transform(df_train)\nresults.iloc[0,1] = multiEval.evaluate(prediction)\nprediction = modelRF.transform(df_train)\nresults.iloc[0,2] = multiEval.evaluate(prediction)\n\nprediction = modelMLP.transform(df_test)\nresults.iloc[1,0] = multiEval.evaluate(prediction)\nprediction = modelDT.transform(df_test)\nresults.iloc[1,1] = multiEval.evaluate(prediction)\nprediction = modelRF.transform(df_test)\nresults.iloc[1,2] = multiEval.evaluate(prediction)"
        }, 
        {
            "source": "## 5.2 Using CrossValidation ##\n### 5.2.1 Setting up CrossValidators - using Model Pipelines ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nparamGrid = ParamGridBuilder().build()\n\ncrossvalMLP = CrossValidator(estimator=pipelineMLP, estimatorParamMaps=paramGrid, evaluator=multiEval, numFolds=5)\ncrossvalDT = CrossValidator(estimator=pipelineDT, estimatorParamMaps=paramGrid, evaluator=multiEval, numFolds=5)\ncrossvalRF = CrossValidator(estimator=pipelineRF, estimatorParamMaps=paramGrid, evaluator=multiEval, numFolds=5)"
        }, 
        {
            "source": "### 5.2.2 Training ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 49, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cvModelMLP = crossvalMLP.fit(df_train)\ncvModelDT = crossvalDT.fit(df_train)\ncvModelRF = crossvalRF.fit(df_train)"
        }, 
        {
            "source": "### 5.2.3 Evaluation ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 50, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 50, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MultiLayerPerceptron</th>\n      <th>DecisionTree</th>\n      <th>RandomForest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>normal_df_train</th>\n      <td>0.976744</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>normal_df_test</th>\n      <td>0.952381</td>\n      <td>0.904762</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>crossVal_df_train</th>\n      <td>0.976744</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>crossVal_df_test</th>\n      <td>0.952381</td>\n      <td>0.904762</td>\n      <td>0.952381</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                  MultiLayerPerceptron DecisionTree RandomForest\nnormal_df_train               0.976744            1            1\nnormal_df_test                0.952381     0.904762     0.952381\ncrossVal_df_train             0.976744            1            1\ncrossVal_df_test              0.952381     0.904762     0.952381"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "prediction = cvModelMLP.transform(df_train)\nresults.iloc[2,0] = multiEval.evaluate(prediction)\nprediction = cvModelDT.transform(df_train)\nresults.iloc[2,1] = multiEval.evaluate(prediction)\nprediction = cvModelRF.transform(df_train)\nresults.iloc[2,2] = multiEval.evaluate(prediction)\n\nprediction = cvModelMLP.transform(df_test)\nresults.iloc[3,0] = multiEval.evaluate(prediction)\nprediction = cvModelDT.transform(df_test)\nresults.iloc[3,1] = multiEval.evaluate(prediction)\nprediction = cvModelRF.transform(df_test)\nresults.iloc[3,2] = multiEval.evaluate(prediction)\nresults"
        }, 
        {
            "source": "# 6. Model improvement #\nLets try to improve the Multilayer Perceptron Model\n## 6.1 Model improvement using Hyperparameter Tuning ##", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 6.1.1 Hyperparameter Tuning Pipeline ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 61, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "resultsTuned = pd.DataFrame(columns = ['TrainingData', 'TestData'], index =['Baseline', 'HyperParamTuning', 'FeatureEngineering1', 'FeatureEngineering2']) \nresultsTuned.iloc[0,0] = results.iloc[0,0]\nresultsTuned.iloc[0,1] = results.iloc[1,0]\nparamGrid = ParamGridBuilder() \\\n    .addGrid(mlp.layers, [[4, 1, 3], [4, 2, 3], [4, 3, 3], [4, 4, 3], [4, 6, 3]]) \\\n    .addGrid(mlp.maxIter, [50, 100, 150]) \\\n    .build()\n#  .addGrid(normalizer.p, [1.0, 2.0, 10.0]) \\\ncrossvalMLP = CrossValidator(estimator=pipelineMLP, estimatorParamMaps=paramGrid, evaluator=multiEval, numFolds=5)"
        }, 
        {
            "source": "### 6.1.2 Hyperparameter Tuning ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 62, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cvModelMLP = crossvalMLP.fit(df_train)\nprediction = cvModelMLP.transform(df_train)\nresultsTuned.iloc[1,0] = multiEval.evaluate(prediction)"
        }, 
        {
            "source": "### 6.1.3 Hyperparameter Tuning Validation ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 63, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 63, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TrainingData</th>\n      <th>TestData</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Baseline</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>HyperParamTuning</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>FeatureEngineering1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>FeatureEngineering2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                    TrainingData  TestData\nBaseline                0.976744  0.952381\nHyperParamTuning        0.976744  0.952381\nFeatureEngineering1          NaN       NaN\nFeatureEngineering2          NaN       NaN"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "prediction = cvModelMLP.transform(df_test)\nresultsTuned.iloc[1,1] = multiEval.evaluate(prediction)"
        }, 
        {
            "source": "## 6.2 Model improvement using PCA transformed Features and Hyperparameter Tuning ##\n### 6.2.1 Alternative Feature Engineering Pipeline using PCA ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 64, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 64, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TrainingData</th>\n      <th>TestData</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Baseline</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>HyperParamTuning</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>FeatureEngineering1</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>FeatureEngineering2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                    TrainingData  TestData\nBaseline                0.976744  0.952381\nHyperParamTuning        0.976744  0.952381\nFeatureEngineering1     0.976744  0.952381\nFeatureEngineering2          NaN       NaN"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from pyspark.ml.feature import PCA\npca = PCA(k=3, inputCol=\"FeaturesNorm\", outputCol=\"FeaturesPCA\")\nmlpPCA = MultilayerPerceptronClassifier(labelCol=\"LabelIndex\", featuresCol=\"FeaturesPCA\", maxIter=100, layers=[3, 3, 3], blockSize=1, seed=123)\npipelinePCAMLP = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, pca, mlpPCA])\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(mlp.layers, [[3, 1, 3], [3, 2, 3], [3, 3, 3]]) \\\n    .addGrid(mlp.maxIter, [50, 100, 150]) \\\n    .build()\n\n#  .addGrid(normalizer.p, [1.0, 2.0, 10.0]) \\\ncrossvalPCAMLP = CrossValidator(estimator=pipelinePCAMLP, estimatorParamMaps=paramGrid, evaluator=multiEval, numFolds=5)\n\ncvModelPCAMLP = crossvalPCAMLP.fit(df_train)\nprediction = cvModelPCAMLP.transform(df_train)\nresultsTuned.iloc[2,0] = multiEval.evaluate(prediction)\n\nprediction = cvModelPCAMLP.transform(df_test)\nresultsTuned.iloc[2,1] = multiEval.evaluate(prediction)"
        }, 
        {
            "source": "### 6.2.2 Alternative Feature Engineering Pipeline using Scaling ###", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 65, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 65, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TrainingData</th>\n      <th>TestData</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Baseline</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>HyperParamTuning</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>FeatureEngineering1</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n    <tr>\n      <th>FeatureEngineering2</th>\n      <td>0.976744</td>\n      <td>0.952381</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                    TrainingData  TestData\nBaseline                0.976744  0.952381\nHyperParamTuning        0.976744  0.952381\nFeatureEngineering1     0.976744  0.952381\nFeatureEngineering2     0.976744  0.952381"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "pipelineScaledMLP = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, mlp])\nparamGrid = ParamGridBuilder() \\\n    .addGrid(mlp.maxIter, [50, 100, 150]) \\\n    .addGrid(normalizer.p, [1.0, 2.0, 10.0]) \\\n    .build()\n\ncvScaledMLP = CrossValidator(estimator=pipelineScaledMLP, estimatorParamMaps=paramGrid, evaluator=multiEval, numFolds=5)\n\ncvScaledMLPModell = cvScaledMLP.fit(df_train)\nprediction = cvScaledMLPModell.transform(df_train)\nresultsTuned.iloc[3,0] = multiEval.evaluate(prediction)\n\nprediction = cvScaledMLPModell.transform(df_test)\nresultsTuned.iloc[3,1] = multiEval.evaluate(prediction)\nresultsTuned"
        }, 
        {
            "source": "# 7. Summary #", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In 5.2.3 Evaluation I got exactly the same results regarding the accuracy of 3 different algorithms for both: \n    (1) classic training \n    (2) crossvalidation training\nAs the evaluation on before unseen data shows, using both training methods resulted in overfitting. This overfitting wasnt observable by using crossvalidation and was detectable only by an evaluation on before unseen data.\nHyperparameter tuning and two feature engineering modifications did unfortunately not result an improved multilayerperceptron model. Beside of that the result are still very good.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# 8. Conclusion#\nConclusion:\nWhenever possible the evaluation should not be based on crossvalidation only, instead evaluation should be done on before unseen data whenever possible.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}